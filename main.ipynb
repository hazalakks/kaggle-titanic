{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef4fc1cc",
   "metadata": {},
   "source": [
    "# Titanic ML\n",
    "This notebook focuses on building machine learning models for the Titanic survival prediction task.\n",
    "The data has already been cleaned and preprocessed in the data analysis notebook, ensuring consistent feature engineering for both train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aa4ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b579cff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Preprocessed Data\n",
    "train_df = pd.read_csv(\"train_preprocessed.csv\")\n",
    "test_df = pd.read_csv(\"test_preprocessed.csv\")\n",
    "\n",
    "# Prepare features and target\n",
    "X = train_df.drop(columns=['Survived', 'PassengerId'])\n",
    "y = train_df['Survived']\n",
    "\n",
    "# Test set (for Kaggle submission)\n",
    "X_test = test_df.drop(columns=['PassengerId'])\n",
    "test_ids = test_df['PassengerId']\n",
    "\n",
    "# Train/Validation Split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f1ccd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic Regression\n",
      "Validation Accuracy: 0.8268156424581006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       110\n",
      "           1       0.79      0.75      0.77        69\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.82      0.81      0.82       179\n",
      "weighted avg       0.83      0.83      0.83       179\n",
      "\n",
      "--------------------------------------------------\n",
      " Random Forest\n",
      "Validation Accuracy: 0.8268156424581006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       110\n",
      "           1       0.80      0.74      0.77        69\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.82      0.81      0.81       179\n",
      "weighted avg       0.83      0.83      0.83       179\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hazal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [10:20:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " XGBoost\n",
      "Validation Accuracy: 0.8156424581005587\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       110\n",
      "           1       0.81      0.68      0.74        69\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.81      0.79      0.80       179\n",
      "weighted avg       0.82      0.82      0.81       179\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model Training & Evaluation\n",
    "\n",
    "def evaluate_model(model, model_name):\n",
    "    \"\"\"Train, evaluate, and return accuracy score.\"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)\n",
    "    acc = accuracy_score(y_valid, y_pred)\n",
    "    \n",
    "    print(f\" {model_name}\")\n",
    "    print(\"Validation Accuracy:\", acc)\n",
    "    print(classification_report(y_valid, y_pred))\n",
    "    print(\"-\" * 50)\n",
    "    return acc\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "acc_lr = evaluate_model(lr_model, \"Logistic Regression\")\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    min_samples_split=4,\n",
    "    random_state=42\n",
    ")\n",
    "acc_rf = evaluate_model(rf_model, \"Random Forest\")\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=4,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "acc_xgb = evaluate_model(xgb_model, \"XGBoost\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a01f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Model Performances\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost'],\n",
    "    'Validation Accuracy': [acc_lr, acc_rf, acc_xgb]\n",
    "})\n",
    "\n",
    "print(\"\\n Model Comparison\")\n",
    "print(results)\n",
    "\n",
    "# Plot results\n",
    "sns.barplot(data=results, x='Model', y='Validation Accuracy')\n",
    "plt.ylim(0.7, 1.0)\n",
    "plt.title(\"Model Performance Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd740910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Best Model on Full Data\n",
    "\n",
    "best_model = xgb_model  # Choose based on results\n",
    "best_model.fit(X, y)\n",
    "\n",
    "# Predict on test set\n",
    "final_preds = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ab4663",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create Kaggle Submission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_ids,\n",
    "    'Survived': final_preds\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Submission file created: submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
